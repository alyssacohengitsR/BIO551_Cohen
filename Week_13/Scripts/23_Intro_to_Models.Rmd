---
title: "23_Intro_to_Models"
output: html_notebook
---


Week 13b
Intro to Models

# Outline of class

Intro to modeling 

1. Intro to basic linear modeling
2. Viewing results in base R, broom, and modelsummary
3. Running many models at the same time with purrr
4. Intro to tidy models


# Libraries
```{r}
library(tidyverse)
library(here)
library(palmerpenguins)
library(broom)
library(performance) # if you didn't already install from group projects install it
library(modelsummary)
library(tidymodels)
```



# Intro to basic linear modeling

## Anatomy of a basic linear model

To run a **simple linear model** you use the following formula: 

`mod<-lm(y~x, data = df)`  

lm = linear model\
y = dependent variable\
x = independent variable(s)\
df = dataframe
\
You read this as *y is a function of x*  
\

**Multiple regression**  
`mod<-lm(y~x1 + x2, data = df)`  
\
**Interaction term**  
`mod<-lm(y~x1*x2, data = df)`  the * will compute x1+x2+x1:x2

## Model the penguin dataset
We've tidied and visualized the data and have our set of hypotheses that we want to test. Now we can start modeling... 

```{r}
penguins %>%
  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species))+
  geom_point()+
  geom_smooth(method = "lm")+
  labs(color = "Species",
       x = "Bill Length (mm)",
       y = "Bill Depth (mm)")+
  theme_bw()
```

```{r}
# Linear model of Bill depth ~ Bill length by species
Peng_mod<-lm(bill_length_mm ~ bill_depth_mm*species, data = penguins)
```


## Check model assumptions with performace

ALWAYS check the assumptions of your specific model. Make sure you know what your model is doing behind the scenes and that you meet all assumptions before interpreting your results.  The [{performance}](https://github.com/easystats/performance) package makes this super easy. 

```{r}
check_model(Peng_mod) # check assumptions of an lm model
```


# View results

## base R

### ANOVA Table

```{r}
anova(Peng_mod)
```

### Coefficients (effect size) with error 

```{r}
summary(Peng_mod)
```


## broom

These results are not in a clean form and it is hard to extract specific values. Using [{broom}](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) we can "tidy" the results so that it is easier to view and extract. 

Functions that will clean up your results:

-   `tidy()`
-   `glance()`
-   `augment()`

### tidy() 
```{r}
# Tidy coefficients
tidy(Peng_mod) # just put tidy() around it

```

### glance() 

**glance** extracts R-squared, AICs, etc of the model
```{r}
# tidy r2, etc
glance(Peng_mod) 
```

### augment()

`augment()` 
add residuals and predicted values to your original data and requires that you put both the model and data
```{r}
# tidy residuals, etc
augment(Peng_mod)
```

## modelsummary

[{modelsummary}](https://vincentarelbundock.github.io/modelsummary/) creates tables and plots to summarize statistical models and data in `R`. 

modelsummary includes two families of functions:

Model Summary  
`modelsummary`: Regression tables with side-by-side models.  
`modelsummary_wide`: Regression tables for categorical response models or grouped coefficients.  
`modelplot`: Coefficient plots.  

Data Summary  
`datasummary`: Powerful tool to create (multi-level) cross-tabs and data summaries.  
`datasummary_balance`: Balance tables with subgroup statistics and difference in means (aka “Table 1”).  
`datasummary_correlation`: Correlation tables.  
`datasummary_skim`: Quick overview (“skim”) of a dataset.  
`datasummary_df`: Turn dataframes into nice tables with titles, notes, etc.  


### Results in `modelsummary()`

**Export** summary tables to word, markdown, or tex document. You can also modify the tables to make them pub quality.  


Let's compare the Peng_mod with one that does not have species as an interaction term.
```{r}
# New model
Peng_mod_noX<-lm(bill_length_mm ~ bill_depth_mm, data = penguins)

#Make a list of models and name them
models<-list("Model with interaction" = Peng_mod,
             "Model with no interaction" = Peng_mod_noX)

#Save the results as a .docx
modelsummary(models, output = here("Week_13","Outputs","table.docx"))

# to view in output as a flextable
modelsummary(models, output = 'flextable') 
```


### Modelplot()

Canned coefficient [modelplots](https://vincentarelbundock.github.io/modelsummary/articles/modelplot.html)

```{r}
library(wesanderson)

modelplot(models) +
    labs(x = 'Coefficients', 
         y = 'Term names') +
    scale_color_manual(values = wes_palette('Darjeeling1'))
```


# Many models with purrr, dplyr, and broom

Let's say you want to plot and compare lots of different models at the same time and view the results. For example, instead of using species as an interaction term, let's make an individual model for every species.

We can essentially make a set of lists that have each dataset that we want to model and use the `map` functions to run the same model to every dataset. We will test it step by step


## nest()

First, let's call the penguin data and create a list for the data by each species.  We do this using `nest()`. We are going to nest the data by species. 

```{r, warning=FALSE}
 models<- penguins %>%
  ungroup()%>% # the penguin data are grouped so we need to ungroup them #<<
    nest(-species) # nest all the data by species #<<

models
```

## map()

map a model to each of the groups in the list
```{r, warning=FALSE}
 models<- penguins %>%
  ungroup()%>% # the penguin data are grouped so we need to ungroup them
  nest(-species) %>% # nest all the data by species 
  mutate(fit = map(data, ~lm(bill_length_mm~body_mass_g, data = .))) #<<
  
  models
```


```{r}
models$fit # shows you each of the 3 models
```

## view results

View the results. First, let's mutate the models list so that we have a tidy coefficient dataframe (using `tidy()`) and a tidy model results dataframe (using `glance()`) 

```{r, warning=FALSE}
results<-models %>%
   mutate(coeffs = map(fit, tidy), # look at the coefficients #<<
          modelresults = map(fit, glance))  # R2 and others #<<
   
results
```

Next, select what we want to show and unnest it to bring it back to a dataframe
```{r, warning=FALSE}
results<-models %>%
   mutate(coeffs = map(fit, tidy), # look at the coefficients
          modelresults = map(fit, glance)) %>% # R2 and others 
   select(species, coeffs, modelresults) %>% # only keep the results #<<
   unnest() # put it back in a dataframe and specify which columns to unnest #<<
results
```

# Other very common stats packages

- `stats`: General (`lm`)and generalized (`glm`) linear models (already loaded with base R)   
- `lmer` : mixed effects models  
- `lmerTest`' : getting results from lmer  
- `nlme` : non-linear mixed effects models  
- `mgcv`, `gam` : generalized additive models  
- `brms`, `rstan`, and many more  : Bayesian modeling  
- `lavaan`, `peicewiseSEM` : Structural Equation Models  
- `rpart`, `randomForest`, `xgboost`, and more : Machine learning models  

And so many more!

Check out [here](https://r4ds.had.co.nz/model-basics.html) for more modeling tips

Also, more info on nest models [here](https://www.kaylinpavlik.com/linear-regression-with-nested-data/) and [here](https://r4ds.had.co.nz/many-models.html)




# Intro to tidy models

{Tidymodels}

Like almost everything else there is a modeling package that uses the tidyverse language to create models. It is called [{tidymodels}](https://www.tidymodels.org/start/models/). For full transparency, I have not used it, but it looks cool and seems particularly useful for machine learning style modeling.


In tidymodels you start by specifying the *functional form* using the [parsnip package](https://tidymodels.github.io/parsnip/). In our case, we will use a *linear regression* which is coded like this:

```{r}
linear_reg()
```


Next, we need to set the *engine* for what type of linear regression we are modeling. For example, we could use an OLS regression or Bayesian or several other options.  We will stick with OLS.

```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") #<<

lm_mod
```


Next, we add the model fit.
```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins) #<<

lm_mod
```


Lastly, we add the `tidy()` to it.  
And now we can pipe this into plots, etc.  Nice, tidy way to model.

```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins) %>%
  tidy()#<<

lm_mod
```


## Pipe to a plot

```{r, out.width="30%", fig.align='center'}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins) %>%
  tidy() %>%
  ggplot()+ #<<
    geom_point(aes(x = term, y = estimate))+ #<<
    geom_errorbar(aes(x = term, ymin = estimate-std.error, #<<
                      ymax = estimate+std.error), width = 0.1 )+ #<<
  coord_flip() #<<

lm_mod
```

